{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1. In the sense of machine learning, what is a model? What is the best way to train a model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "The machine learning model is a program automatically written or created or learned by the machine \n",
    "learning algorithm to solve our problem.A machine learning model is a file that has been trained to\n",
    "recognize certain types of patterns. Best way to train model is to keep a check on overfitting while\n",
    "using tools like cross validation,evaluate the model and adjust the hyper parameters accordingly\n",
    "have the data which is representative and does not have missing values.The optimal model for a given \n",
    "problem is one that  has enough bias to avoid simply memorizing the training data and enough variance \n",
    "to actually fit the patterns in the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2. In the sense of machine learning, explain the No Free Lunch theorem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "The “no free lunch” (NFL) theorem for supervised machine learning is a theorem that essentially implies \n",
    "that no single machine learning algorithm is universally the best-performing algorithm for all problems.\n",
    "Some algorithms may generally perform better than others on certain types of problems, but every algorithm\n",
    "has disadvantages and advantages due to the prior assumptions that come with that algorithm.The best models\n",
    "for a given problem are somewhere in the middle of the two bias-variance extremes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "3. Describe the K-fold cross-validation mechanism in detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cross-validation is a resampling procedure used to evaluate machine learning models on a limited data \n",
    "sample. The procedure has a single parameter called k that refers to the number of groups that a given \n",
    "data sample is to be split into.The k-fold cross validation is implemented by taking the amount of \n",
    "observations, n, and randomly splitting them into k, non-overlapping groups of length of approximately \n",
    "n/k. These groups acts as a validation set, and the remainder acts as a training set. The test error is \n",
    "then estimated by averaging the k resulting MSE estimates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "4. Describe the bootstrap sampling method. What is the aim of it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Bootstrap sampling is used in a machine learning ensemble algorithm called bootstrap aggregating (also \n",
    "called bagging). It helps in avoiding overfitting and improves the stability of machine learning algorithms.\n",
    "In bagging, a certain number of equally sized subsets of a dataset are extracted with replacement. Then, a \n",
    "machine learning algorithm is applied to each of these subsets and the outputs are ensembled.Bootstrapping \n",
    "is a statistical procedure that resamples a single dataset to create many simulated samples. This process \n",
    "allows you to calculate standard errors, construct confidence intervals, and perform hypothesis testing \n",
    "for numerous types of sample statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "5. What is the significance of calculating the Kappa value for a classification model? Demonstrate\n",
    "how to measure the Kappa value of a classification model using a sample collection of results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "The Kappa statistic (or value) is a metric that compares an Observed Accuracy with an Expected Accuracy \n",
    "(random chance). The kappa statistic is used not only to evaluate a single classifier, but also to \n",
    "evaluate classifiers amongst themselves. In addition, it takes into account random chance (agreement with\n",
    "a random classifier), which generally means it is less misleading than simply using accuracy as a metric \n",
    " Computation of Observed Accuracy and Expected Accuracy is integral to comprehension of the kappa statistic,\n",
    "and is most easily illustrated through use of a confusion matrix.\n",
    "Cohen’s kappa removes the possibility of the classifier and a random guess agreeing and measures the number\n",
    "of predictions it makes that cannot be explained by a random guess. Furthermore, Cohen’s kappa tries to \n",
    "correct the evaluation bias by taking into account the correct classification by a random guess.Cohen’s \n",
    "kappa is more informative than overall accuracy when working with unbalanced data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "6. Describe the model ensemble method. In machine learning, what part does it play?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ensemble methods are meta-algorithms that combine several machine learning techniques into one predictive \n",
    "model in order to decrease variance (bagging), bias (boosting), or improve predictions (stacking).\n",
    "Ensemble methods are techniques that create multiple models and then combine them to produce improved \n",
    "results. Ensemble methods usually produces more accurate solutions than a single model would. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "7. What is a descriptive model's main purpose? Give examples of real-world problems that\n",
    "descriptive models were used to solve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A descriptive model describes a system or other entity and its relationship to its environment. It is \n",
    "generally used to help specify and/or understand what the system is, what it does, and how it does it. A \n",
    "geometric model or spatial model is a descriptive model that represents geometric and/or spatial \n",
    "relationships.The process is used by consumer-driven organizations to help them target their marketing \n",
    "and advertising efforts.n descriptive modeling, customer groups are clustered according to demographics, \n",
    "purchasing behavior, expressed interests and other descriptive factors. Statistics can identify where the \n",
    "customer groups share similarities and where they differ. The most active customers get special attention \n",
    "because they offer the greatest ROI (return on investment)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "8. Describe how to evaluate a linear regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Mean Squared Error (MSE)\n",
    "The most common metric for regression tasks is MSE. It has a convex shape. It is the average of the squared\n",
    "difference between the predicted and actual value. Since it is differentiable and has a convex shape, it is\n",
    "easier to optimize.\n",
    "Mean Absolute Error (MAE)\n",
    "This is simply the average of the absolute difference between the target value and the value predicted by \n",
    "the model. Not preferred in cases where outliers are prominent.\n",
    "A linear algorithm often has high bias, which makes them learn fast. In linear regression analysis, bias \n",
    "refers to the error that is introduced by approximating a real-life problem, which may be complicated, by\n",
    "a much simpler model.\n",
    "High variance may lead to overfitting in linear regression there is always a trade off between bias and\n",
    "variance and hence best model has optimal balance between the both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "9. Distinguish :\n",
    "\n",
    "1. Descriptive vs. predictive models\n",
    "\n",
    "2. Underfitting vs. overfitting the model\n",
    "\n",
    "3. Bootstrapping vs. cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A descriptive model will exploit the past data that are stored in databases and provide you with the \n",
    "accurate report. In a Predictive model, it identifies patterns found in past and transactional data to \n",
    "find risks and future outcomes.\n",
    "\n",
    "Model is underfitting the training data when the model performs poorly on the training data. This is \n",
    "because the model is unable to capture the relationship between the input examples (often called X) and \n",
    "the target values (often called Y). Your model is overfitting your training data when you see that the \n",
    "model performs well on the training data but does not perform well on the evaluation data. This is because\n",
    "the model is memorizing the data it has seen and is unable to generalize to unseen examples.\n",
    "\n",
    "Due to the drawing with replacement, a bootstrapped data set may contain multiple instances of the same \n",
    "original cases, and may completely omit other original cases.cross validation resamples without replacement\n",
    "and thus produces surrogate data sets that are smaller than the original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "10. Make quick notes on:\n",
    "\n",
    "1. LOOCV.\n",
    "\n",
    "2. F-measurement\n",
    "\n",
    "3. The width of the silhouette\n",
    "\n",
    "4. Receiver operating characteristic curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOOCV is an extreme version of k-fold cross-validation that has the maximum computational cost. It requires\n",
    "one model to be created and evaluated for each example in the training dataset.LOOCV is appropriate when \n",
    "an accurate estimate of model performance is critical. This particularly case when the dataset is small, \n",
    "such as less than thousands of examples, can lead to model overfitting during training and biased estimates\n",
    "of model performance.\n",
    "\n",
    "F-score or F-measure is a measure of a test's accuracy. It is calculated from the precision and recall of\n",
    "the test, where the precision is the number of true positive results divided by the number of all \n",
    "positive results, including those not identified correctly, and the recall is the number of true \n",
    "positive results divided by the number of all samples that should have been identified as positive.\n",
    "\n",
    "Silhouette width is also an estimate of the average distance between clusters.\n",
    "The silhouette value is a measure of how similar an object is to its own cluster (cohesion) compared to other \n",
    "clusters (separation). The silhouette ranges from −1 to +1, where a high value indicates that the object is\n",
    "well matched to its own cluster and poorly matched to neighboring clusters. If most objects have a high\n",
    "value, then the clustering configuration is appropriate. If many points have a low or negative value, then\n",
    "the clustering configuration may have too many or too few clusters.The silhouette can be calculated with \n",
    "any distance metric, such as the Euclidean distance or the Manhattan distance.\n",
    "\n",
    "A receiver operating characteristic curve, or ROC curve, is a graphical plot that illustrates the \n",
    "diagnostic ability of a binary classifier system as its discrimination threshold is varied.\n",
    "An ROC curve (receiver operating characteristic curve) is a graph showing the performance of a \n",
    "classification model at all classification thresholds. This curve plots two parameters: True Positive Rate.\n",
    "False Positive Rate.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
